{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "# Hyper Parameters\n",
    "num_epochs = 2\n",
    "batch_size = 1\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST Dataset\n",
    "train_dataset = dsets.MNIST(root='./data/',\n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data/',\n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model (2 conv layer)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "#         self.layer1 = nn.Sequential(\n",
    "#             nn.Conv2d(1, 1, kernel_size=3, padding=2),\n",
    "#             nn.BatchNorm2d(16),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2)\n",
    "#         )\n",
    "        self.layer1 = nn.Conv2d(1,1, kernel_size=4, padding=4)\n",
    "        self.layer1.weight.data = torch.Tensor([[0,-1,1,0],[-1,-3,3,0],[-1,-3,3,0],[0,-1,1,0]]).unsqueeze(0).unsqueeze(0)\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.fc = nn.Linear(7*7*32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        print('convb weights',self.layer1.weight.data)\n",
    "        return out\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "        \n",
    "cnn = CNN()\n",
    "cnn.cuda()\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git config --global user.name 'missglory'\n",
    "!git config --global user.email 'xhaustful@gmail.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convb weights \n",
      "(0 ,0 ,.,.) = \n",
      "  0 -1  1  0\n",
      " -1 -3  3  0\n",
      " -1 -3  3  0\n",
      "  0 -1  1  0\n",
      "[torch.cuda.FloatTensor of size 1x1x4x4 (GPU 0)]\n",
      "\n",
      "out shape  torch.Size([1, 1, 33, 33])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 1: only batches of spatial targets supported (3D tensors) but got targets of dimension: 1 at c:\\anaconda2\\conda-bld\\pytorch_1519501749874\\work\\torch\\lib\\thcunn\\generic/SpatialClassNLLCriterion.cu:14",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-8a4fd70d2288>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'out shape '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    677\u001b[0m         \u001b[0m_assert_no_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m         return F.cross_entropy(input, target, self.weight, self.size_average,\n\u001b[1;32m--> 679\u001b[1;33m                                self.ignore_index, self.reduce)\n\u001b[0m\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce)\u001b[0m\n\u001b[0;32m   1159\u001b[0m         \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m     \"\"\"\n\u001b[1;32m-> 1161\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce)\u001b[0m\n\u001b[0;32m   1052\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: invalid argument 1: only batches of spatial targets supported (3D tensors) but got targets of dimension: 1 at c:\\anaconda2\\conda-bld\\pytorch_1519501749874\\work\\torch\\lib\\thcunn\\generic/SpatialClassNLLCriterion.cu:14"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAE2JJREFUeJzt3W1sZFd9x/Hv3+NnrxPb8WbjbLZdEtJCGsEmWFFKKkSB0jSiDZEKAlU0LyIWVUQCFaRGoSqpxAuoCigvENVSIkKhgRRI2VZpS5RSUYQU4kCyu2EhCcmSbNbsA/vk3awfZubfF3NXcsP5X8/a85D1+X0ky+Nz58w9vvZv7sw9c84xd0dE8tPT7QaISHco/CKZUvhFMqXwi2RK4RfJlMIvkimFXyRTCr9IphR+kUz1rqWymd0I3A1UgH9090+W3b8yOuK9G8fWsksRKVE9fJza3Glr5r6rDr+ZVYDPAX8A7AceNbOd7v6TcGcbx7j0Ex9c7S5FZAUH/vpzTd93LS/7rwOecfdn3X0R+Bpw8xoeT0Q6aC3h3wy8sOzn/UWZiJwH1hL+1PuKXxsiaGbbzWzGzGZqc6fXsDsRaaW1hH8/sGXZz5cBB15+J3ff4e7T7j5dGR1Zw+5EpJXWEv5HgSvN7FVm1g+8B9jZmmaJSLut+mq/u1fN7Hbgv2h09d3j7k+2rGUi0lZr6ud39weBB1vUFhHpIH3CTyRTCr9IphR+kUwp/CKZUvhFMqXwi2RK4RfJlMIvkimFXyRTCr9IphR+kUwp/CKZUvhFMqXwi2RK4RfJlMIvkimFXyRTCr9IphR+kUwp/CKZUvhFMqXwi2RK4RfJlMIvkqk1LdphZvuAOaAGVN19uhWNEpH2W1P4C7/v7kda8Dgi0kF62S+SqbWG34HvmNljZra9FQ0Skc5Y68v+G9z9gJldDDxkZj919+8tv0PxpLAdoDJ54Rp3JyKtsqYzv7sfKL4fAh4ArkvcZ4e7T7v7dGV0ZC27E5EWWnX4zWzEzEbP3gbeDuxpVcNEpL3W8rJ/E/CAmZ19nH929/9sSavOI41fP1XuJXXibbVa+vl4cGgxrLO0mP4zRo8F4NWSbfX0L2W99bhOLTgQQE9UL64iHbDq8Lv7s8DrW9gWEekgdfWJZErhF8mUwi+SKYVfJFOt+Gz/ulepxFe5h4Kr8LV6/LxaD66mAyzNp/8kY5NnwjpHqhvS+znWF9bpO14Jt/Uspdu3OBYfh975+HeqjlXTGzyuY8PpOtYT95TIudGZXyRTCr9IphR+kUwp/CKZUvhFMqXwi2RKXX1N2Dg+F2675qIXk+X/++LlYZ3Tx+OhzZVj6T/JwYELwjp+cDBZPnAyfm7vi38lLBqHU9J9WfZ4L1XS3YpDv4wfb2EiXWfpoqDbEOgZibfJr9OZXyRTCr9IphR+kUwp/CKZUvhFMqWr/U24emI23HbLxEyy/D9+dlVYp3+2ZMDNXHqwy9L8UFhndF+6fP6isAoLEyVTiQ2nt/UslgzEqcbbKlteSj/e/vSAJICJJ9NtWBiPj93xbfHv1DNYC7flSmd+kUwp/CKZUvhFMqXwi2RK4RfJlMIvkqkVu/rM7B7gHcAhd7+6KJsAvg5sBfYB73b3Y+1rZndVSlbYubSSHtFStiLO4OGSbrH59L48WhoI6FlK11naELd7aWM8CKZvQ3pewqUzcTdbdSLcxN3XfiNZ/qGTfxbWueDB9PEbf+JoWOfkFWNxI9TV92uaOfN/CbjxZWV3AA+7+5XAw8XPInIeWTH8xZLbL3+6vRm4t7h9L/DOFrdLRNpste/5N7n7LEDx/eLWNUlEOqHtF/zMbLuZzZjZTG3udLt3JyJNWm34D5rZFEDx/VB0R3ff4e7T7j5dGY1nsBGRzlpt+HcCtxa3bwW+3ZrmiEinNNPVdx/wZmDSzPYDHwc+CdxvZrcBzwPvamcju23P0alw2yOjW5Plo2PpkWwAPYsD4bZ6X7pLr2wUXjV4QbW4qWS+u6Fzn++ub2gp3FY2z+GfjKSPxV+NzYd15sfSI/6Gn/xZWKf31PXhtupksCHuQV33Vgy/u7832PTWFrdFRDpIn/ATyZTCL5IphV8kUwq/SKY0h18TfnlsNNx2X+91yfL+3nggydymeF9Lo+nlcnwivtJeq6cvWff0x23o64+v9teq6dVyJkuu6F9x4ZFw27+eTl+5nz9SMi9hsGoQFp+vekrmEXRPb7OSQVvrnc78IplS+EUypfCLZErhF8mUwi+SKYVfJFPq6mtCvZbu+gJ47nB68rqSKfdYvDTutusZTHfB9ZV0263G+Gg88Oj4qeFk+cbheD6G5+fiSfw+duDmZPnIvvjfb/SFhWS5X391WGdxLOofBOvJt0svojO/SKYUfpFMKfwimVL4RTKl8ItkSlf7m+AlF4qjQTBlVjOF1tbJeKWahVr6z3j0pXjgzOmF/nDb/PHBZPlTvjGss3go3UMA0H80fY7Z9GR8HHpfSveIHHhTepAQgI+newgg69m6Qjrzi2RK4RfJlMIvkimFXyRTCr9IphR+kUw1s2LPPcA7gEPufnVRdhfwfuBwcbc73f3BdjVS4I2Tz4bb6kFH1ld2p+cXBPCjcVdf/8n0OaF2NO5m65+PO9N6gzFEw/tOhnXmXnNhsvz05njwjpybZs78XwJuTJR/1t23FV8Kvsh5ZsXwu/v3gPgTJiJyXlrLe/7bzWyXmd1jZuPRncxsu5nNmNlMbS4eDy4inbXa8H8euALYBswCn47u6O473H3a3acro8FysiLScasKv7sfdPeau9eBLwDxlSUReUVaVfjNbPmC9bcAe1rTHBHplGa6+u4D3gxMmtl+4OPAm81sG+DAPuADbWyjAKdqA+G2Px77cbL8y4u/G9YZOB4/71uw/FdlPqxSaumC9LDIpcl4JOCpqfRoyaGD8X6qJ+Puy8XN6VGCZUuarXcrht/d35so/mIb2iIiHaRP+IlkSuEXyZTCL5IphV8kU5rD7zzx/YOXh9veMLIvWd43vBjWqY7Ef3oLLoD3nl7dTHjDVx9Lls+ejlf5WZhID+AZOhifryaeiydbPLGY7gk4c3k8719P3/oeRKQzv0imFH6RTCn8IplS+EUypfCLZErhF8mUuvrOE0eOjYbbvjJ7fbK8Uom7vpYm0gNdAKilu/RqA6v7d/mdiSPJ8seujOd3uOSS48lyvyrublx6IF5ObOoH6S69/QPxYKCl30jXsZ6S9dvOIzrzi2RK4RfJlMIvkimFXyRTCr9IphR+kUypq+88UQ/m1QN4+mC6i6tei5/bS0es9aWLvXd1XVxP/yrdvrI2XDWenqzvo5d8J6zzjqf+Mtx28c4XkuUXbrkirHN4U3oeQRuqhnXOJzrzi2RK4RfJlMIvkimFXyRTCr9IpppZsWcL8GXgEqAO7HD3u81sAvg6sJXGqj3vdvf0ZG3SVtWl9FXpVrPe1c1pd+rUYLK8ty9eLWdq8ESyvGJxj0N9OH48P3EyWd53uuR3CgY4rRfNnPmrwEfc/bXA9cAHzewq4A7gYXe/Eni4+FlEzhMrht/dZ939R8XtOWAvsBm4Gbi3uNu9wDvb1UgRab1zes9vZluBa4BHgE3uPguNJwjg4qDOdjObMbOZ2tzptbVWRFqm6fCb2Qbgm8CH3T39BirB3Xe4+7S7T1dG48kbRKSzmgq/mfXRCP5X3f1bRfFBM5sqtk8Bh9rTRBFphxXDb2ZGY0nuve7+mWWbdgK3FrdvBb7d+uaJSLs0M7DnBuB9wG4ze7wouxP4JHC/md0GPA+8qz1NbC0r6b3pH0jPa3fmRLqrCsCCwSnrZZ63VoiOxW9fEr9Y/K3B2WT5p2b/MKzTdzT+d67PzyfLq0Ml57/K+hjAE1kx/O7+fSCKzFtb2xwR6RR9wk8kUwq/SKYUfpFMKfwimcpuGq/oij7AtqkXk+WP/vw1YR0Pnj7rGxfDOqsdIPNK1tcfXxkfCLbdtHF3WOep+alk+X/vfm1YZ+K5cBM9w8PJ8jOTcfdP1JOzXujML5IphV8kUwq/SKYUfpFMKfwimVL4RTKVXVffxIaXwm1/vukHyfInTsTdS0OH0oNWjvUGy94A9bG4u9Eq5z4gqFODiCqVuOvr4gtPhdsmh9LbnltIr+QD8MBPX58sH3o+Pq4X7Yn/tvXXvTpZ/tJUfOys5PddD3TmF8mUwi+SKYVfJFMKv0imFH6RTCn8IpnKrquvrxIv6bSl93iy/MylcZ3+E+mlsvpPxKPFagv94bZ6b7rrqR73cFEfDNq32qf2oPerZ0PcRdlTsozWL06MJ8t/vHdrWKf/cPpfc+BXYRV6j58Jtx1640SyvDZe9jvF+1oPdOYXyZTCL5IphV8kUwq/SKYUfpFMrXi138y2AF8GLgHqwA53v9vM7gLeDxwu7nqnuz/Yroa2ypFT8WKh9x2/Llk+9erDyXKAIxs3JMuXjgyFdUaeS/cQANT70peYq8Px1fTaYvrPaKscl+LB4KLambjdvziZXKQZgL5j6Xrjz8dtOLMxfRzM4+Nw9Jp0rwLAifS4nnU/T1+ZZrr6qsBH3P1HZjYKPGZmDxXbPuvuf9++5olIuzSzXNcsMFvcnjOzvcDmdjdMRNrrnN7zm9lW4BrgkaLodjPbZWb3mFnyNZeZbTezGTObqc2dXlNjRaR1mg6/mW0Avgl82N1PAp8HrgC20Xhl8OlUPXff4e7T7j5dGY3fb4tIZzUVfjProxH8r7r7twDc/aC719y9DnwBSF8tE5FXpBXDb2YGfBHY6+6fWVa+fEmVW4A9rW+eiLRLM1f7bwDeB+w2s8eLsjuB95rZNhrDQPYBH2hLC1vszJl4UM2/7bs6WT46uBDWecNlLyTLn7sgPZAE4MTspnBbdSTdlbU0Hg8uIpjDr3Ii/vP2lDxcLRhEVDZYqTIf7yvqcqwNxG1YHE9Xqg2WDJhKr8gFgI+ll09bzZyJ60UzV/u/D6SO+Cu+T19EYvqEn0imFH6RTCn8IplS+EUyld00Xl6PrxafOjWYLF8IBs4ALFTT20b601eXARYm48Ek9eH0ZfihiXiKqsiZSvr3AahV4+PQM1xNli95fHm+HneixFOT9Zdcab8wPb3WUi0+X/X0xV0Yts6n5FoNnflFMqXwi2RK4RfJlMIvkimFXyRTCr9IprLr6luNpZKuvmPV9Px0p/pKusUuSHelAfT0p7urqkvx/HnhYw2UjN4pGVRTqaS7IqvjcfflUkkXatjNFgxIArBgm5WsuCTnRmd+kUwp/CKZUvhFMqXwi2RK4RfJlMIvkil19a1RNEpwcaFk/rygO69MrWQ0W6tF+yqb7y7nufDOVzrzi2RK4RfJlMIvkimFXyRTCr9IpppZrmvQzH5oZk+Y2ZNm9rdF+avM7BEze9rMvm5mJbO4icgrTTNn/gXgLe7+ehor8t5oZtcDnwI+6+5XAseA29rXTBFptRXD7w2nih/7ii8H3gJ8oyi/F3hnW1ooIm3R7BLdlWKRzkPAQ8DPgePufnZg+n5gc1B3u5nNmNlMbe50K9osIi3QVPjdvebu24DLgOuA16buFtTd4e7T7j5dGR1ZfUtFpKXO6Wq/ux8H/ge4Hhgzs7OfYb0MONDapolIOzVztX+jmY0Vt4eAtwF7ge8Cf1rc7Vbg2+1qpIi0XjMDe6aAe82sQuPJ4n53/3cz+wnwNTP7BPBj4IttbKeItNiK4Xf3XcA1ifJnabz/F5HzkD7hJ5IphV8kUwq/SKYUfpFMKfwimVL4RTKl8ItkSuEXyZTCL5IphV8kUwq/SKbMvXMrrZjZYeAXxY+TwJGO7TxNbVAb1lsbftPdNzZzx46G///t2GzG3ae7snO1QW1QG/SyXyRXCr9IproZ/h1d3PdZakOD2tCQVRu69p5fRLpLL/tFMtWV8JvZjWb2MzN7xszu6FIb9pnZbjN73MxmOrTPe8zskJntWVY2YWYPFcuePWRm411ow11m9mJxLB43s5vauP8tZvZdM9tbLP/2oaK8Y8ehpA2dPA7dXwbP3Tv6BVRoLPpxOdAPPAFc1YV27AMmO7zPNwHXAnuWlf0dcEdx+w7gU11ow13ARzt0DKaAa4vbo8BTwFWdPA4lbejkcTBgQ3G7D3iExpT49wPvKcr/AfiLdrWhG2f+64Bn3P1Zd18Evgbc3IV2dJy7fw84+rLim2ksdwYdWPYsaEPHuPusu/+ouD1HYxr4zXTwOJS0oWO8oavL4HUj/JuBF5b9HC711WYOfMfMHjOz7V3Y/1mb3H0WGv+UwMVdasftZrareFvQ1rceZ5nZVhozQz9Cl47Dy9oAHTwOa1kGrxW6EX5LlHWjy+EGd78W+CPgg2b2pi604ZXi88AVNFZhngU+3e4dmtkG4JvAh939ZLv312QbOnocfA3L4LVCN8K/H9iy7OeuLPXl7geK74eAB+jeGgQHzWwKoPh+qNMNcPeDxT9iHfgCbT4WZtZHI3RfdfdvFcUdPQ6pNnT6OJzlXVoGrxvhfxS4sriq2Q+8B9jZyQaY2YiZjZ69Dbwd2FNeq2120ljuDLq07NnZ0BVuoY3HwsyMxupOe939M8s2dew4RG3o8HHo/jJ4nbiymbjSeRONK6w/Bz7Whf1fTqOX4QngyU61AbiPxsvJJRqvgG4DLgIeBp4uvk90oQ3/BOwGdtEI4VQb9/97NF7K7gIeL75u6uRxKGlDJ4/D62gsc7eLxpPM3yz73/wh8AzwL8BAu9qgT/iJZEqf8BPJlMIvkimFXyRTCr9IphR+kUwp/CKZUvhFMqXwi2Tq/wDIvCpbu3QBbAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the Model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images).cuda()\n",
    "        labels = Variable(labels).cuda()\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(images)\n",
    "#         print('image', images.data)\n",
    "        plt.imshow(images.data.squeeze().cpu().numpy())\n",
    "        plt.figure()\n",
    "        \n",
    "#         print('outputs', outputs.shape)\n",
    "        outs = outputs.data.squeeze().cpu().numpy()\n",
    "        plt.imshow(outs)\n",
    "        print('out shape ', outputs.shape)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Model\n",
    "cnn.eval()    # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images).cuda()\n",
    "    outputs = cnn(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted.cpu() == labels).sum()\n",
    "\n",
    "print('Test Accuracy of the model on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "# Save the Trained Model\n",
    "torch.save(cnn.state_dict(), 'cnn.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastAI custom",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
